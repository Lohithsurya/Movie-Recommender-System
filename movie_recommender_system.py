# -*- coding: utf-8 -*-
"""Movie_recommender_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JH-qJNwbrTPU_yFLOf9p4j14j2mR3hCo
"""

import numpy as np
import pandas as pd
import ast

movies = pd.read_csv('./movies/tmdb_5000_movies.csv')
credits = pd.read_csv('./movies/tmdb_5000_credits.csv')

movies = movies.merge(credits, on ='title')

#genres, id, keywords, original_title, overview (coz content based recom, if will be good if the summary is same), cast,crew

movies = movies[['id','title','overview', 'genres','keywords', 'cast', 'crew' ]]
"""Data Preprocessing (creating a new datafram with 3 columns => id, title, tags )"""

movies.dropna(inplace=True)

movies.iloc[0].genres

def convert (obj):
  L = []
  for i in ast.literal_eval(obj):
    L.append(i['name'])
  return L

movies['genres'] = movies['genres'].apply(convert)



movies['keywords'] = movies['keywords'].apply(convert)



def convert_cast (obj):
  L = []
  counter = 0
  for i in ast.literal_eval(obj):
    if counter != 3:
      L.append(i['name'])
      counter+=1
    else:
      break
  return L

movies['cast'] = movies['cast'].apply(convert_cast)



def fetch_director(obj):
  L =[]
  for i in ast.literal_eval(obj):
    if i['job'] == 'Director':
      L.append(i['name'])
      break
  return L

movies['crew'] = movies['crew'].apply(fetch_director)



movies['overview'] = movies['overview'].apply(lambda x:x.split())



movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])
movies['cast'] = movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])
movies['crew'] = movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])

movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']
movies['tags'] = movies['tags'].apply(lambda x:" ".join(x))
movies['tags'] = movies['tags'].apply(lambda x: x.lower())




import nltk
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
  y=[]
  for i in text.split():
    y.append(ps.stem(i))

  return " ".join(y)

movies['tags'] = movies['tags'].apply(stem)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000, stop_words = 'english')

vectors = cv.fit_transform(movies['tags']).toarray()



cv.get_feature_names_out()

from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)

sorted(list(enumerate(similarity[2])),reverse=True,key = lambda x: x[1])[1:6]


def recommend(movie, criteria="tags"):
    # Map criteria to the appropriate column and similarity matrix
    feature_column = {
        "story": "overview",
        "genres": "genres",
        "keywords": "keywords",
        "actors": "cast",
        "director": "crew",
        "tags": "tags",  # Default
    }.get(criteria.lower(), "tags")

    if feature_column not in movies.columns:
        raise KeyError(f"The column '{feature_column}' is missing in the dataset.")

    # Use precomputed similarity matrix based on selected criteria
    similarity_matrix = similarity.get(feature_column)
    
    if similarity_matrix is None:
        raise ValueError(f"No similarity matrix found for the selected feature: {criteria}")
    
    # Find the movie index
    try:
        movie_index = movies[movies["title"] == movie].index[0]
    except IndexError:
        raise ValueError(f"The movie '{movie}' was not found in the dataset.")

    distances = similarity_matrix[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]

    # Get recommendations
    recommended_movies = [movies.iloc[i[0]].title for i in movies_list]
    for i in recommended_movies:
        print(i)

# Example Usage
recommend('Batman Begins', criteria='director')  # Recommendations based on director


recommend('Batman Begins')


